{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ML Engineer Mini Project_Problem A_Krishna Chaitanya.ipynb",
      "provenance": [],
      "mount_file_id": "1KgufikKxog2NrApAGgMY-Y_GlB7iZpRC",
      "authorship_tag": "ABX9TyN4GL2SijJUwIwEzK/BjrRB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kchaitanya954/Machine-learning-technologies/blob/main/ML_Engineer_Mini_Project_Problem_A_Krishna_Chaitanya.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSK6-l05JeZu"
      },
      "source": [
        "# import libraries\n",
        "#!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
        "#!pip install fastai\n",
        "import fastai\n",
        "from fastai import *\n",
        "from fastai.text import * \n",
        "from functools import partial\n",
        "import io\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "HCMEAulSLGWY",
        "outputId": "e25f0d32-3d84-417e-fd41-ea7be4a45abc"
      },
      "source": [
        "df = pd.read_csv('drive/MyDrive/Colab Notebooks/JEOPARDY_CSV.csv',na_values=['None'])\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(216930, 7)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Show Number</th>\n",
              "      <th>Air Date</th>\n",
              "      <th>Round</th>\n",
              "      <th>Category</th>\n",
              "      <th>Value</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>HISTORY</td>\n",
              "      <td>$200</td>\n",
              "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
              "      <td>Copernicus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
              "      <td>$200</td>\n",
              "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
              "      <td>Jim Thorpe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
              "      <td>$200</td>\n",
              "      <td>The city of Yuma in this state has a record av...</td>\n",
              "      <td>Arizona</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>THE COMPANY LINE</td>\n",
              "      <td>$200</td>\n",
              "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
              "      <td>McDonald's</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
              "      <td>$200</td>\n",
              "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
              "      <td>John Adams</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Show Number  ...      Answer\n",
              "0         4680  ...  Copernicus\n",
              "1         4680  ...  Jim Thorpe\n",
              "2         4680  ...     Arizona\n",
              "3         4680  ...  McDonald's\n",
              "4         4680  ...  John Adams\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEVfkSKNMtew",
        "outputId": "a28e4e14-0aa1-4546-c5ac-b13c469b6d73"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Show Number       0\n",
              " Air Date         0\n",
              " Round            0\n",
              " Category         0\n",
              " Value         3634\n",
              " Question         0\n",
              " Answer           3\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRwE2-UPNKlW"
      },
      "source": [
        "df = df.dropna()\n",
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCXEzJCRNZg4"
      },
      "source": [
        "df['ValueNum'] = df[' Value'].apply(lambda value: int(value.replace(',', '').replace('$', '')))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-yOl-KuQGRc"
      },
      "source": [
        "def binning(value):\n",
        "    if value < 1000:\n",
        "        return np.round(value, -2)\n",
        "    elif value < 10000:\n",
        "        return np.round(value, -3)\n",
        "    else:\n",
        "        return np.round(value, -4)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q26PzyzjQV1r"
      },
      "source": [
        "df['ValueBins'] = df['ValueNum'].apply(binning)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnL4RJHaHu5-"
      },
      "source": [
        "df[' Question'] = df[' Question'].str.replace(\"[^a-zA-Z]\", \" \")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLsqfZrTH7E_",
        "outputId": "2cd41dce-28da-4ea0-ee70-da978e77c8e5"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords \n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Pyy_sF4H8yv"
      },
      "source": [
        "# tokenization \n",
        "tokenized_doc = df[' Question'].apply(lambda x: x.split())\n",
        "\n",
        "# remove stop-words \n",
        "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xeemre5IYcj"
      },
      "source": [
        "# de-tokenization \n",
        "detokenized_doc = [] \n",
        "for i in range(len(df)): \n",
        "    t = ' '.join(tokenized_doc[i]) \n",
        "    detokenized_doc.append(t) \n",
        "\n",
        "df[' Question'] = detokenized_doc"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wDM006VPh5S"
      },
      "source": [
        "df = df[[' Question', 'ValueBins']]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lly7ocb8QBxm",
        "outputId": "185e8171-e69a-4456-cebf-41ce6a23be36"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 213293 entries, 0 to 213292\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count   Dtype \n",
            "---  ------     --------------   ----- \n",
            " 0    Question  213293 non-null  object\n",
            " 1   ValueBins  213293 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 3.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5SKUw07PBic"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split data into training and validation set\n",
        "df_trn, df_val = train_test_split(df, stratify = df['ValueBins'], test_size = 0.2, random_state = 12)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwDL9JRVQIIj",
        "outputId": "4a48a14b-d63c-4719-e381-1bf2bc5af7fe"
      },
      "source": [
        "print(df_trn.shape, df_val.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(170634, 2) (42659, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "CDEIlgMqQRh6",
        "outputId": "61762d0a-a614-4ca1-9804-2d2217c46429"
      },
      "source": [
        "# Language model data\n",
        "data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = \"\")\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD-muliUfAV3"
      },
      "source": [
        "ULMFiT Transfer learning model is used.\n",
        "This method involves fine-tuning a pre-trained language model (LM), trained on the Wikitext 103 dataset, to a new dataset in such a manner that it does not forget what it previously learned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kku9h6MNQZRH"
      },
      "source": [
        "learn = language_model_learner(data_lm,  arch = AWD_LSTM, pretrained = True, drop_mult=0.7)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "7WDawUPYRGI0",
        "outputId": "998b8c30-d906-41b3-8a9d-b54b068dcd56"
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.412118</td>\n",
              "      <td>1.066365</td>\n",
              "      <td>0.598583</td>\n",
              "      <td>00:12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAUbuC1eYLe3"
      },
      "source": [
        "learn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYkCKq9aek4b"
      },
      "source": [
        "The accuracy of the model is 60%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA0XryqhWsFy",
        "outputId": "4b563c49-ca96-4e62-fc6e-a26b8b758ad6"
      },
      "source": [
        "!nvidia-smi\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Mar 18 17:20:58 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    28W /  70W |   1690MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXastnWiWvnI",
        "outputId": "a0aa1475-353f-4f1e-e881-42da08c50313"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulF5W1_lWyQc",
        "outputId": "5c3a8eb1-066a-4b9d-f80f-7fc87be2be9a"
      },
      "source": [
        "!git clone --depth 1 -b v2.4.0 https://github.com/tensorflow/models.git"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 752, done.\u001b[K\n",
            "remote: Counting objects: 100% (752/752), done.\u001b[K\n",
            "remote: Compressing objects: 100% (651/651), done.\u001b[K\n",
            "remote: Total 752 (delta 166), reused 371 (delta 91), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (752/752), 1.22 MiB | 12.58 MiB/s, done.\n",
            "Resolving deltas: 100% (166/166), done.\n",
            "Note: checking out '47e65c1aedf4181faaf5535f06c26dbcb083c4ad'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14Z_jE7gpPYV",
        "outputId": "72d110cb-22fc-46e9-e9ea-f336be09a199"
      },
      "source": [
        "# install requirements to use tensorflow/models repository\n",
        "!pip install -Uqr models/official/requirements.txt\n",
        "# you may have to restart the runtime afterwards"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 6.5MB 9.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 225kB 52.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 9.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 15.3MB 154kB/s \n",
            "\u001b[K     |████████████████████████████████| 9.9MB 34.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 296kB 55.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 13.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 27.4MB 103kB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 56.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.7MB 50.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 706kB 49.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 58.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 11.6MB 50.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 645kB 51.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 37.6MB 183kB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2MB 43.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 44.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 12.2MB/s \n",
            "\u001b[?25h  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.20.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pandas-gbq 0.13.3 has requirement google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1, but you'll have google-cloud-bigquery 2.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.2.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-cloud-storage 1.18.1 has requirement google-resumable-media<0.5.0dev,>=0.3.1, but you'll have google-resumable-media 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Clipa0prpqGm"
      },
      "source": [
        "!pip install tf-models-official"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP14_AbqWzXM"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import sys\n",
        "sys.path.append('models')\n",
        "from official.nlp.data import classifier_data_lib\n",
        "from official.nlp.bert import tokenization\n",
        "from official.nlp import optimization"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGNE68vcW4aD",
        "outputId": "7e3e7758-ec2f-4b03-c643-bddb8c77bd33"
      },
      "source": [
        "train_df, valid_df = train_test_split(df, random_state=1, train_size = 0.8, stratify = df.ValueBins.values)\n",
        "train_df.shape, valid_df.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((170634, 2), (42659, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oOyy91iXECF",
        "outputId": "0a06b54d-79c8-4158-b8ef-d78925185c82"
      },
      "source": [
        "with tf.device('/cpu:0'):\n",
        "  train_data = tf.data.Dataset.from_tensor_slices((train_df[' Question'].values, train_df['ValueBins'].values))\n",
        "  valid_data = tf.data.Dataset.from_tensor_slices((valid_df[' Question'].values, valid_df['ValueBins'].values))\n",
        "\n",
        "  for text, label in train_data.take(1):\n",
        "    print(text)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'VIDEO DAILY DOUBLE Hi I Chuck Woolery Going date people pay known type treat', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvHXV34gXN4g"
      },
      "source": [
        "label_list= sorted(df.ValueBins.unique())\n",
        " # maximum length of (token) input sequences\n",
        "max_seq_length = 50\n",
        "train_batch_size =32\n",
        "\n",
        "# Get BERT layer and tokenizer:\n",
        "# More details here: https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\", trainable=True)\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agLIdO9aXbkm"
      },
      "source": [
        "def to_feature(text, label, label_list=label_list, max_seq_length=max_seq_length, tokenizer=tokenizer):\n",
        "  example = classifier_data_lib.InputExample(guid = None, text_a=text.numpy(), text_b=None, label=label.numpy())\n",
        "\n",
        "  feature = classifier_data_lib.convert_single_example(0, example, label_list, max_seq_length, tokenizer)\n",
        "\n",
        "  return (feature.input_ids, feature.input_mask, feature.segment_ids, feature.label_id)\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3unmuuzlXf8I"
      },
      "source": [
        "def to_feature_map(text, label):\n",
        "  \n",
        "  input_ids, input_mask, segment_ids, label_id = tf.py_function(to_feature, inp= [text, label], Tout=[tf.int32, tf.int32, tf.int32, tf.int32])\n",
        "\n",
        "  input_ids.set_shape([max_seq_length])\n",
        "  input_mask.set_shape([max_seq_length])\n",
        "  segment_ids.set_shape([max_seq_length])\n",
        "  label_id.set_shape([])\n",
        "\n",
        "  x={\n",
        "      'input_word_ids':input_ids,\n",
        "     'input_mask': input_mask,\n",
        "     'input_type_ids': segment_ids\n",
        "  }\n",
        "  return (x, label_id)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15piIgE-Xg5a"
      },
      "source": [
        "with tf.device('/cpu:0'):\n",
        "  # train\n",
        "  train_data= (train_data.map(to_feature_map, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  .shuffle(1000)\n",
        "  .batch(32, drop_remainder=True)\n",
        "  .prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  )\n",
        "\n",
        "  # valid\n",
        "  valid_data= (valid_data.map(to_feature_map, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  .batch(32, drop_remainder=True)\n",
        "  .prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  )"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw3u2PzwXmwt"
      },
      "source": [
        "# Building the model\n",
        "def create_model():\n",
        "  input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                       name=\"input_word_ids\")\n",
        "  input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                   name=\"input_mask\")\n",
        "  input_type_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                    name=\"input_type_ids\")\n",
        "  pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, input_type_ids])\n",
        "\n",
        "  drop = tf.keras.layers.Dropout(0.4)(pooled_output)\n",
        "\n",
        "  output = tf.keras.layers.Dense(21, activation='softmax', name=\"output\")(drop)\n",
        "\n",
        "  model = tf.keras.Model(inputs={'input_word_ids': input_word_ids, 'input_mask': input_mask, 'input_type_ids':input_type_ids},\n",
        "                         outputs = output)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wklCnvmXrrA",
        "outputId": "867133be-7f7e-4c24-9b3c-2a1f5ed6a966"
      },
      "source": [
        "model= create_model()\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2),\n",
        "                    loss= tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                    metrics= ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_type_ids (InputLayer)     [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 input_type_ids[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 768)          0           keras_layer[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 21)           16149       dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 109,498,390\n",
            "Trainable params: 109,498,389\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ6xYV-WX-0k",
        "outputId": "977aa23b-fb0d-4d84-a2f1-ebc7ea41325d"
      },
      "source": [
        "history = model.fit(train_data, validation_data=valid_data, epochs=2, verbose=1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "5332/5332 [==============================] - 1890s 352ms/step - loss: 3.4005 - accuracy: 0.1406 - val_loss: 2.6624 - val_accuracy: 0.1494\n",
            "Epoch 2/2\n",
            "5332/5332 [==============================] - 1873s 351ms/step - loss: 3.3344 - accuracy: 0.1427 - val_loss: 3.1987 - val_accuracy: 0.1494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG9A_tIMqPYA",
        "outputId": "388cd5a4-cc81-4f5d-e390-a62c3e0ae6ed"
      },
      "source": [
        "sample_texts =['who is worlds best cricketer']\n",
        "test_data= tf.data.Dataset.from_tensor_slices((sample_texts, [0]*(len(sample_texts))))\n",
        "test_data= (test_data.map(to_feature_map).batch(1))\n",
        "preds= model.predict(test_data)\n",
        "\n",
        "np.argmax(preds,axis=1)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7KvsSZo9-FW"
      },
      "source": [
        "ULMFiT Transfer learning model gives better accuracy for the data"
      ]
    }
  ]
}